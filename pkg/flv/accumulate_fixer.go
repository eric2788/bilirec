package flv

import (
	"bytes"
	"sync"
)

// =====================================================
// ACCUMULATE FIXER - ç´¯ç© X MB å¾Œæ‰¹æ¬¡è™•ç†
// =====================================================

type AccumulateFixer struct {
	mu             sync.Mutex
	tsStore        *TimestampStore
	buffer         *bytes.Buffer
	chunkSizeBytes int
	headerWritten  bool
	totalProcessed int64

	// ğŸ”¥ å„ªåŒ–: é åˆ†é… tag slice
	tagCache     []*Tag
	tagCacheSize int

	// ğŸ”¥ æ–°å¢: å»é‡æ”¯æŒ
	dedupCache *DedupCache
	dupCount   int64
}

func NewAccumulateFixer(chunkSizeMB int) *AccumulateFixer {

	// ğŸ”¥ å„ªåŒ–:  ä¼°ç®—å¯èƒ½çš„ tag æ•¸é‡ä¸¦é åˆ†é…
	estimatedTags := (chunkSizeMB * 1024 * 1024) / 1024 // å‡è¨­å¹³å‡ 1KB/tag

	return &AccumulateFixer{
		tsStore:        &TimestampStore{FirstChunk: true},
		buffer:         new(bytes.Buffer),
		chunkSizeBytes: chunkSizeMB * 1024 * 1024,
		headerWritten:  false,
		tagCache:       make([]*Tag, 0, estimatedTags),
		tagCacheSize:   estimatedTags,
		dedupCache:     NewDedupCache(MaxDedupCacheSize, DedupWindowMs), // ğŸ”¥ åˆå§‹åŒ–å»é‡
		dupCount:       0,
	}
}

// ğŸ”¥ æ–°å¢: ç²å–å»é‡çµ±è¨ˆ
func (af *AccumulateFixer) GetDedupStats() (duplicates int64, cacheSize int, cacheCapacity int) {
	af.mu.Lock()
	defer af.mu.Unlock()

	size, capacity := af.dedupCache.GetStats()
	return af.dupCount, size, capacity
}

// Accumulate adds data and returns true if ready to flush
func (af *AccumulateFixer) Accumulate(input []byte) (bool, error) {
	af.mu.Lock()
	defer af.mu.Unlock()

	af.buffer.Write(input)
	return af.buffer.Len() >= af.chunkSizeBytes, nil
}

// Flush processes accumulated data (call this when Accumulate returns true OR at EOF)
func (af *AccumulateFixer) Flush() ([]byte, error) {
	af.mu.Lock()
	defer af.mu.Unlock()

	return af.flushInternal()
}

// FlushRemaining processes all remaining data (call at EOF)
func (af *AccumulateFixer) FlushRemaining() ([]byte, error) {
	af.mu.Lock()
	defer af.mu.Unlock()

	// Force flush even if buffer is small
	return af.flushInternal()
}

// ğŸ”¥ å„ªåŒ–:  é‡‹æ”¾è³‡æº
func (af *AccumulateFixer) Close() {
	af.mu.Lock()
	defer af.mu.Unlock()

	if af.buffer != nil {
		af.buffer.Reset()
		byteBufferPool.Put(af.buffer)
		af.buffer = nil
	}

	// è¿”é‚„æ‰€æœ‰ tag åˆ° pool
	for _, tag := range af.tagCache {
		if tag != nil {
			tagPool.Put(tag)
		}
	}
	af.tagCache = nil

	if af.dedupCache != nil {
		af.dedupCache.Reset()
	}
}

func (af *AccumulateFixer) flushInternal() ([]byte, error) {
	if af.buffer.Len() == 0 {
		return nil, nil
	}

	// ğŸ”¥ å„ªåŒ–: å¾ pool å–å¾— output buffer
	output := byteBufferPool.Get().(*bytes.Buffer)
	output.Reset()

	// Write header once globally (not per flush)
	if !af.headerWritten {
		if af.buffer.Len() < 9 {
			// Not enough data yet, keep waiting
			return nil, nil
		}

		header := make([]byte, 9)
		copy(header, af.buffer.Bytes()[:9])

		if !bytes.Equal(header[:3], []byte{'F', 'L', 'V'}) {
			return nil, ErrNotFlvFile
		}

		output.Write(header)
		output.Write([]byte{0, 0, 0, 0})
		af.headerWritten = true
		af.buffer.Next(9) // Consume header from buffer
	}

	// Parse all complete tags
	// ğŸ”¥ å„ªåŒ–: é‡ç”¨ tag cache
	tags := af.tagCache[:0] // ä¿ç•™å®¹é‡ï¼Œæ¸…ç©ºé•·åº¦

	for af.buffer.Len() >= 15 {
		startLen := af.buffer.Len()

		// Skip PreviousTagSize
		// ğŸ”¥ å„ªåŒ–: å¾ pool å–å¾—å° buffer
		prevTagSizeBytes := smallBytesPool.GetBuffer()
		af.buffer.Read(prevTagSizeBytes)

		if af.buffer.Len() < TagHeaderSize {
			// Restore
			tempBuf := byteBufferPool.Get().(*bytes.Buffer)
			tempBuf.Reset()
			tempBuf.Write(prevTagSizeBytes)
			tempBuf.Write(af.buffer.Bytes())
			af.buffer.Reset()
			af.buffer.Write(tempBuf.Bytes())
			tempBuf.Reset()
			byteBufferPool.Put(tempBuf)
			smallBytesPool.PutBuffer(prevTagSizeBytes)
			break
		}

		headerBytes := headerBytesPool.GetBuffer()
		af.buffer.Read(headerBytes)

		dataSize := uint32(headerBytes[1])<<16 | uint32(headerBytes[2])<<8 | uint32(headerBytes[3])

		if af.buffer.Len() < int(dataSize) {
			// Incomplete tag, restore buffer
			tempBuf := byteBufferPool.Get().(*bytes.Buffer)
			tempBuf.Reset()
			tempBuf.Write(prevTagSizeBytes)
			tempBuf.Write(headerBytes)
			tempBuf.Write(af.buffer.Bytes())
			af.buffer.Reset()
			af.buffer.Write(tempBuf.Bytes())
			tempBuf.Reset()
			byteBufferPool.Put(tempBuf)
			headerBytesPool.PutBuffer(headerBytes)
			smallBytesPool.PutBuffer(prevTagSizeBytes)
			break
		}

		tagData := make([]byte, dataSize)
		af.buffer.Read(tagData)

		timestamp := int32(headerBytes[7])<<24 | int32(headerBytes[4])<<16 |
			int32(headerBytes[5])<<8 | int32(headerBytes[6])

		// ğŸ”¥ å„ªåŒ–:  å¾ pool å–å¾— tag
		tag := tagPool.Get().(*Tag)
		tag.Reset()
		tag.Type = headerBytes[0]
		tag.DataSize = dataSize
		tag.Timestamp = timestamp
		tag.Data = tagData
		copy(tag.StreamID[:], headerBytes[8:11])

		if len(tagData) >= 2 {
			if tag.Type == TagTypeVideo {
				tag.IsKeyframe = (tagData[0] & 0xF0) == 0x10
				tag.IsHeader = tagData[1] == 0x00
			} else if tag.Type == TagTypeAudio && (tagData[0]>>4) == 10 {
				tag.IsHeader = tagData[1] == 0x00
			}
		}

		// ğŸ”¥ æ–°å¢:  å»é‡æª¢æŸ¥
		if af.dedupCache.IsDuplicate(tag) {
			af.dupCount++
			tagPool.Put(tag)
			headerBytesPool.PutBuffer(headerBytes)
			smallBytesPool.PutBuffer(prevTagSizeBytes)
			continue // è·³éé‡è¤‡çš„ tag
		}

		tags = append(tags, tag)

		headerBytesPool.PutBuffer(headerBytes)
		smallBytesPool.PutBuffer(prevTagSizeBytes)

		// Safety check
		if af.buffer.Len() > startLen {
			return nil, ErrBufferCorrupted
		}
	}

	// Fix timestamps for all tags
	af.fixTimestamps(tags)

	// Write all fixed tags
	for _, tag := range tags {
		if err := writeTagOptimized(output, tag); err != nil {
			return nil, err
		}
	}

	af.totalProcessed += int64(output.Len())

	// ğŸ”¥ æ–°å¢: å®šæœŸæ¸…ç†éæœŸå»é‡è¨˜éŒ„
	if len(tags) > 0 {
		lastTimestamp := tags[len(tags)-1].Timestamp
		af.dedupCache.CleanOld(lastTimestamp)
	}

	// ğŸ”¥ å„ªåŒ–: ä¿å­˜ tag cache ä¾›ä¸‹æ¬¡ä½¿ç”¨
	af.tagCache = tags

	// ğŸ”¥ å„ªåŒ–: è¿”å›è¤‡è£½çš„æ•¸æ“š
	result := make([]byte, output.Len())
	copy(result, output.Bytes())

	output.Reset()
	byteBufferPool.Put(output)

	return result, nil
}

func (af *AccumulateFixer) fixTimestamps(tags []*Tag) {
	if len(tags) == 0 {
		return
	}

	ts := af.tsStore

	// First chunk:  find minimum timestamp
	if ts.FirstChunk {
		ts.FirstChunk = false
		minTs := tags[0].Timestamp
		for _, t := range tags {
			if t.Timestamp < minTs {
				minTs = t.Timestamp
			}
		}
		ts.CurrentOffset = minTs
	}

	for _, tag := range tags {
		currentTimestamp := tag.Timestamp
		diff := currentTimestamp - ts.LastOriginal

		if diff < -JumpThreshold || (ts.LastOriginal == 0 && diff < 0) {
			ts.CurrentOffset = currentTimestamp - ts.NextTimestampTarget
		} else if diff > JumpThreshold {
			ts.CurrentOffset = currentTimestamp - ts.NextTimestampTarget
		}

		ts.LastOriginal = tag.Timestamp
		tag.Timestamp -= ts.CurrentOffset
	}

	ts.NextTimestampTarget = CalculateNextTargetAdvanced(tags)
}

// GetStats returns processing statistics
func (af *AccumulateFixer) GetStats() (buffered int, processed int64) {
	af.mu.Lock()
	defer af.mu.Unlock()
	return af.buffer.Len(), af.totalProcessed
}
